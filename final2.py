import pandas as pd
import numpy as np
import mplfinance as mpf
from itertools import product
from scipy.stats import spearmanr
import seaborn as sns
import matplotlib.pyplot as plt
import time

# ---------------------------
# 1. CSV ë¡œë“œ í•¨ìˆ˜
# ---------------------------
def load_csv(path, timestamp_col="timestamp"):
    df = pd.read_csv(path)
    df[timestamp_col] = pd.to_datetime(df[timestamp_col], unit='ms', utc=True)
    df = df.sort_values(timestamp_col).reset_index(drop=True)
    df.set_index(timestamp_col, inplace=True)
    return df

# ---------------------------
# 2. 1ì°¨íŠ¸ ë³€ë™ì„± ì ìˆ˜(IQR)
# ---------------------------
def onechart_score(df_1min, df_1chart, shift=1, lookback=100, k=1.5):
    df_score = df_1min.copy()
    per_min_std = df_1chart['fx_diff'].astype(float).resample("1min").std().reindex(df_score.index)
    base = per_min_std.shift(shift)
    Q1 = base.rolling(lookback, min_periods=1).quantile(0.25)
    Q3 = base.rolling(lookback, min_periods=1).quantile(0.75)
    IQR = Q3 - Q1
    upper = Q3 + k*IQR
    over = (per_min_std - upper).clip(lower=0)
    df_score["onechart_volatility"] = over / (IQR + 1e-12)
    df_score["onechart_volatility"] = df_score["onechart_volatility"].fillna(0)
    return df_score

# ---------------------------
# 3. IQR + Z-score + 1ì°¨íŠ¸ í†µí•© ì´ìƒì¹˜ ì ìˆ˜
# ---------------------------
def detect_anomalies_combined(df_1min, df_1chart, lookback=100, k_ret=1.5):
    df = df_1min.copy()
    df["ret"] = df["close"].pct_change().fillna(0)

    iqr_scores = []
    z_scores = []

    for i in range(len(df)):
        start = max(0, i-lookback)
        window = df["ret"].iloc[start:i+1]

        # IQR score
        q1 = window.quantile(0.25)
        q3 = window.quantile(0.75)
        iqr = q3 - q1
        lower = q1 - k_ret*iqr
        upper = q3 + k_ret*iqr
        val = df["ret"].iloc[i]
        iqr_score = max(0, val - upper) + max(0, lower - val)
        iqr_scores.append(iqr_score)

        # Z-score
        hist_mean = window.mean()
        hist_std = window.std()
        if hist_std > 0:
            z_score = abs(val - hist_mean) / hist_std
            z_score = min(1.0, z_score / 3.0)  # 0~1ë¡œ ì •ê·œí™”
        else:
            z_score = 0.0
        z_scores.append(z_score)

    df["iqr_score"] = iqr_scores
    df["z_score"] = z_scores

    # 1ì°¨íŠ¸ ë³€ë™ì„± ì ìˆ˜
    df_score = onechart_score(df, df_1chart)

    # ìµœì¢… ê°€ì¤‘í•©
    df_score["final_conf_0.5_0.3_0.2"] = (
        df_score["iqr_score"]*0.5 +
        df_score["onechart_volatility"]*0.3 +
        df_score["z_score"]*0.2
    )

    return df_score

# ---------------------------
# 4. Grid Search 
# ---------------------------
def grid_search_combined(df_1min, df_1chart, lookback_list, threshold_list, weight_list):
    results = []
    for lookback, threshold, price_weight in product(lookback_list, threshold_list, weight_list):
        df_score = detect_anomalies_combined(df_1min, df_1chart, lookback=lookback, k_ret=threshold)
        a = df_score["iqr_score"].fillna(0)*price_weight + df_score["z_score"].fillna(0)*(1-price_weight)
        b = df_score["onechart_volatility"].fillna(0)
        corr, _ = spearmanr(a, b)
        results.append({
            "lookback": lookback,
            "threshold": threshold,
            "price_weight": price_weight,
            "volume_weight": 1-price_weight,
            "correlation": corr
        })
    df_result = pd.DataFrame(results).sort_values("correlation", ascending=False)
    return df_result

# ---------------------------
# 5. ì‹œê°í™”
# ---------------------------
def plot_anomaly_score(df, idx, q=0.95, anomaly_key="final_conf_0.5_0.3_0.2", title=""):
    threshold = df[anomaly_key].quantile(q)
    score_points = np.where(df[anomaly_key] > threshold, df['close'], np.nan)
    add_plots = [mpf.make_addplot(score_points[idx[0]:idx[1]], type='scatter', marker='o', markersize=10, color='blue')]
    chart_title = title if title else f"Anomaly Detection (Threshold: {threshold:.4f})"
    mpf.plot(df.iloc[idx[0]:idx[1]], type='candle', style='yahoo', addplot=add_plots, volume=True, title=chart_title)

# ---------------------------
# 6. ìƒê´€ê³„ìˆ˜ Heatmap ê·¸ë¦¬ê¸°
# ---------------------------
def plot_correlation_heatmap(results_df):
    # 'lookback'ì„ ì„¸ë¡œì¶•ìœ¼ë¡œ, 'price_weight'ì„ ê°€ë¡œì¶•ìœ¼ë¡œ, 'correlation' ê°’ì„ í‘œì‹œ
    pivot_table = results_df.pivot_table(
        index="lookback",  # ì„¸ë¡œì¶•: lookback
        columns="price_weight",   # ê°€ë¡œì¶•: price_weight
        values="correlation",     # ê°’: correlation
        aggfunc="mean"            # í‰ê· ê°’ìœ¼ë¡œ ì§‘ê³„
    )

    # Heatmap ì‹œê°í™”
    plt.figure(figsize=(8, 6))  # í¬ê¸° ì„¤ì •

    # íˆíŠ¸ë§µì„ ê·¸ë¦¬ë©´ì„œ ìŠ¤íƒ€ì¼ ì¡°ì •
    sns.heatmap(pivot_table, 
                annot=True, 
                fmt=".6f",  # ì†Œìˆ˜ì  3ìë¦¬ë¡œ í¬ë§·íŒ…
                cmap="YlGnBu",  # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
                cbar_kws={'label': 'Spearman Correlation'},  # ìƒ‰ìƒ ë§‰ëŒ€ ë ˆì´ë¸”
                linewidths=0.8,  # ê²©ìì„  ë‘ê»˜
                square=True)  # ì •ì‚¬ê°í˜• ë¹„ìœ¨ ìœ ì§€

    # ì œëª©, ì¶• ë ˆì´ë¸” ì„¤ì •
    plt.title(f"{coin} Grid Search Correlation Heatmap", fontsize=14, weight='bold')
    plt.xlabel("Price Weight", fontsize=12, labelpad=10)
    plt.ylabel("Lookback Window", fontsize=12, labelpad=10)

    # ì—¬ë°± ì¡°ì •
    plt.tight_layout()
    plt.show()

# ---------------------------
# 7. ì‹¤í–‰ 
# ---------------------------
if __name__ == "__main__":
    start_time = time.time()
    coin = 'yfi'  # ê°„í¸í•˜ê²Œ ë³€ê²½í•  ìˆ˜ ìˆë„ë¡ ë³€ìˆ˜ ì„¤ì •
    
    paths_1min = {f'./candle_data/{coin}.csv': f"{coin}"}
    for path_1min, symbol in paths_1min.items():
        print("------------------------------------")
        print(f"\n1. {symbol} ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        path_1chart = path_1min.replace(".csv","_1chart.csv")
        df_1min = load_csv(path_1min)
        df_1chart = load_csv(path_1chart)

        # GridSearch ë²”ìœ„
        print("2. GridSearch í•˜ëŠ” ì¤‘...")
        lookback_list = [50, 70, 100]
        threshold_list = [0.7]
        weight_list = [0.3, 0.5, 0.7]

        search_result = grid_search_combined(df_1min, df_1chart, lookback_list, threshold_list, weight_list)
        print(f"\nğŸ“Œ [{symbol}] GridSearch Top 5 Results:")
        print(search_result.head())
        
        best_lookback = int(search_result.iloc[0]["lookback"])
        print(f"Grid Search ê²°ê³¼ {symbol} ì¢…ëª©ì€ lookbackì´ {best_lookback}ì¼ ë•Œ ì œì¼ ì•ˆì •ì ì´ë¼ê³  íŒë‹¨")  

        # ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ì´ìƒì¹˜ íƒì§€
        print("\n3. ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ì´ìƒì¹˜ íƒì§€í•˜ëŠ” ì¤‘...")
        best = search_result.iloc[0]
        df_final = detect_anomalies_combined(df_1min, df_1chart, lookback=int(best["lookback"]), k_ret=best["threshold"])

        # ê²°ê³¼ ì‹œê°í™”
        print("4. ê²°ê³¼ ì‹œê°í™”í•˜ëŠ” ì¤‘...")
        plot_anomaly_score(df_final, idx=[100,300], q=0.95, anomaly_key="final_conf_0.5_0.3_0.2",
                           title=f"{symbol} - Final Anomaly Score (0.5+0.3+0.2)")
        
        # ìƒê´€ê³„ìˆ˜ Heatmap ê·¸ë¦¬ê¸°
        print("5. ìƒê´€ê³„ìˆ˜ Heatmap ì‹œê°í™” ì¤‘...\n")
        plot_correlation_heatmap(search_result)  # ìµœì ì˜ íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ê²°ê³¼ë¡œ heatmap ê·¸ë¦¬ê¸°
        
        end_time = time.time()
        print(f"\nâ±ï¸ ì´ ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")